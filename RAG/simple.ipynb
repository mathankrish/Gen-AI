{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f69750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61cb1b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b94e131c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groq_api = os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7366b2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000018B6E5FE6C0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000018B6E640350>, model_name='deepseek-r1-distill-llama-70b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"deepseek-r1-distill-llama-70b\",api_key=groq_api)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "597480d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nAlright, the user wants to translate \"Hello, how are you?\" into French. Let me break this down. \"Hello\" in French is \"Bonjour.\" That\\'s straightforward. Now, \"how are you?\" can be translated in a couple of ways. The most common is \"Comment ça va?\" which is pretty casual and widely used. Another option is \"Comment allez-vous?\" but that\\'s more formal. Since the original sentence is a friendly greeting, \"Comment ça va?\" fits better. So putting it together, the translation would be \"Bonjour, comment ça va?\" I think that\\'s the best fit for this context.\\n</think>\\n\\nBonjour, comment ça va ?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 139, 'prompt_tokens': 16, 'total_tokens': 155, 'completion_time': 0.628389409, 'prompt_time': 0.000530728, 'queue_time': 0.050481102, 'total_time': 0.628920137}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--150ffcf6-5817-42fe-8b5f-b742a1880b52-0', usage_metadata={'input_tokens': 16, 'output_tokens': 139, 'total_tokens': 155})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Message\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "messages= [\n",
    "\n",
    "    HumanMessage(content=\"Hello,how are you?\"),\n",
    "    SystemMessage(content=\"Convert the Given sentence to French\")\n",
    "]\n",
    "result=model.invoke(messages)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e178e48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nAlright, the user wants to translate \"Hello, how are you?\" into French. Let me break this down. \"Hello\" in French is \"Bonjour.\" That\\'s straightforward. Now, \"how are you?\" can be translated in a couple of ways. The most common is \"Comment ça va?\" which is pretty casual and widely used. Another option is \"Comment allez-vous?\" but that\\'s more formal. Since the original sentence is a friendly greeting, \"Comment ça va?\" fits better. So putting it together, the translation would be \"Bonjour, comment ça va?\" I think that\\'s the best fit for this context.\\n</think>\\n\\nBonjour, comment ça va ?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parsing the output\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser= StrOutputParser()\n",
    "parser.invoke(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82c35438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nAlright, I need to translate \"Hello, how are you?\" into French. Let me break it down.\\n\\n\"Hello\" in French is \"Bonjour.\" That\\'s straightforward.\\n\\nNext, \"how are you\" translates to \"comment allez-vous?\" which is the formal way to ask.\\n\\nPutting it together, it becomes \"Bonjour, comment allez-vous?\" That sounds polite and correct.\\n</think>\\n\\nBonjour, comment allez-vous ?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Using LCEL(LangChain Expression Language)- chain the components\n",
    "chain=model|parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdc7f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prompt Templates\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "generic_template=\"Trnaslate the following into {language}:\"\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [(\"system\",generic_template),(\"user\",\"{text}\")]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2ba3ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=prompt.invoke({\"language\":\"French\",\"text\":\"Hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8ce7268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Trnaslate the following into French:', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hello', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b59c1da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\n\\n</think>\\n\\nBonjour'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Chaining together components with LCEL\n",
    "chain=prompt|model|parser\n",
    "chain.invoke({\"language\":\"French\",\"text\":\"Hello\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70854957",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
